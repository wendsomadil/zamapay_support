#!/usr/bin/env python3
"""
RESPONSE_GENERATOR - ZAMAPAY
G√©n√©rateur de r√©ponses intelligentes avec RAG et Gemini
"""

import random
import json
import time
import google.generativeai as genai
from web_searcher import WebSearcher

class ResponseGenerator:
    def __init__(self, retrieval_system):
        """
        Initialise le g√©n√©rateur de r√©ponses
        
        Args:
            retrieval_system: Syst√®me RAG pour la recherche de connaissances
        """
        self.retrieval_system = retrieval_system
        self.web_searcher = WebSearcher()
        self.conversation_memory = {}
        self.escalation_threshold = 0.4
        
        # Cache pour optimiser les performances
        self.web_cache = {}
        self.cache_timeout = 3600  # 1 heure
        
        # Configuration Gemini
        self.gemini_api_key = "AIzaSyBge8Q1B4g-rT5nIuhIb4Dc99BuIZXy7Ak"
        self._setup_gemini()
        
        # Templates conversationnels
        self.conversation_templates = self._init_quality_templates()

    def _setup_gemini(self):
        """Configure l'API Gemini avec gestion d'erreurs"""
        try:
            genai.configure(api_key=self.gemini_api_key)
            self.gemini_model = genai.GenerativeModel('gemini-2.5-flash')
            print("‚úÖ Gemini configur√© avec succ√®s")
        except Exception as e:
            print(f"‚ùå Erreur configuration Gemini: {e}")
            self.gemini_model = None

    def generate_response(self, user_message, user_name=None):
        """
        G√©n√®re une r√©ponse conversationnelle naturelle avec RAG
        
        Args:
            user_message (str): Message de l'utilisateur
            user_name (str, optional): Nom de l'utilisateur pour le contexte
            
        Returns:
            dict: R√©ponse structur√©e avec m√©tadonn√©es
        """
        print(f"üí¨ Conversation: '{user_message}'")
        
        # 1. Analyse du contexte et de l'intention
        conversation_context = self._get_conversation_context(user_name)
        intent = self._analyze_intent(user_message)
        
        # 2. Recherche RAG optimis√©e
        rag_results = self._enhanced_rag_search(user_message, intent)
        
        # 3. Fallback Gemini si n√©cessaire
        if self._should_use_gemini_fallback(rag_results):
            print("üîç Aucune r√©ponse trouv√©e, utilisation de Gemini...")
            gemini_response = self._generate_with_gemini_fallback(user_message)
            if gemini_response:
                return self._format_gemini_response(gemini_response)
        
        # 4. G√©n√©ration de r√©ponse adapt√©e √† l'intention
        response = self._generate_intent_based_response(user_message, rag_results, intent, conversation_context)
        
        # 5. Mise √† jour du contexte conversationnel
        self._update_conversation_memory(user_name, user_message, response)
        
        return response

    def _should_use_gemini_fallback(self, rag_results):
        """D√©termine si on doit utiliser Gemini comme fallback"""
        return (not rag_results["knowledge_base"] and 
                not rag_results["web_search"] and 
                self.gemini_model)

    def _format_gemini_response(self, response_text):
        """Formate une r√©ponse Gemini"""
        return {
            'type': 'success',
            'response': response_text,
            'confidence': 0.8,
            'source': 'gemini_fallback'
        }

    def _enhanced_rag_search(self, user_message, intent):
        """
        Recherche RAG am√©lior√©e avec cache et multiples sources
        
        Args:
            user_message (str): Question de l'utilisateur
            intent (str): Intention d√©tect√©e
            
        Returns:
            dict: R√©sultats de recherche avec scores de confiance
        """
        results = {
            "knowledge_base": [],
            "web_search": [],
            "gemini_analysis": None,
            "confidence": 0.0
        }
        
        # Recherche dans la base de connaissances
        self._search_knowledge_base(user_message, results)
        
        # Recherche web avec cache
        self._search_web_with_cache(user_message, intent, results)
        
        # Analyse Gemini pour questions complexes
        self._search_gemini_analysis(user_message, intent, results)
        
        return results

    def _search_knowledge_base(self, user_message, results):
        """Recherche dans la base de connaissances"""
        kb_results = self.retrieval_system.search(user_message)
        if kb_results:
            results["knowledge_base"] = kb_results
            results["confidence"] = max(results["confidence"], kb_results[0]['score'])

    def _search_web_with_cache(self, user_message, intent, results):
        """Recherche web avec syst√®me de cache"""
        cache_key = user_message.lower().strip()
        current_time = time.time()
        
        # V√©rifier le cache
        if (cache_key in self.web_cache and 
            current_time - self.web_cache[cache_key]['timestamp'] < self.cache_timeout):
            print("üíæ Utilisation du cache web")
            results["web_search"] = self.web_cache[cache_key]['results']
            if results["web_search"]:
                results["confidence"] = max(results["confidence"], 0.6)
        else:
            # Recherche web si n√©cessaire
            if intent in ["complex_analysis", "comparison"] or results["confidence"] < 0.5:
                try:
                    print("üåê Recherche web pour:", user_message)
                    web_results = self.web_searcher.search_web(user_message, num_results=2)
                    results["web_search"] = web_results
                    
                    # Mettre en cache
                    self.web_cache[cache_key] = {
                        'results': web_results,
                        'timestamp': current_time
                    }
                    
                    if web_results:
                        results["confidence"] = max(results["confidence"], 0.6)
                except Exception as e:
                    print(f"‚ö†Ô∏è Recherche web √©chou√©e: {e}")

    def _search_gemini_analysis(self, user_message, intent, results):
        """Analyse Gemini pour questions complexes"""
        if intent in ["complex_analysis", "problem_solving"] and self.gemini_model:
            try:
                context = self._build_rag_context(results)
                gemini_response = self._generate_with_gemini(user_message, context)
                if gemini_response:
                    results["gemini_analysis"] = gemini_response
                    results["confidence"] = max(results["confidence"], 0.9)
            except Exception as e:
                print(f"‚ö†Ô∏è Analyse Gemini √©chou√©e: {e}")

    def _generate_intent_based_response(self, user_message, rag_results, intent, context):
        """
        G√©n√®re une r√©ponse bas√©e sur l'intention d√©tect√©e
        """
        response_strategies = {
            "simple_fact": lambda: self._generate_simple_response(user_message, rag_results),
            "complex_analysis": lambda: self._generate_analytical_response(user_message, rag_results, context),
            "comparison": lambda: self._generate_comparison_response(user_message, rag_results),
            "problem_solving": lambda: self._generate_solution_response(user_message, rag_results),
            "general": lambda: self._generate_natural_response(user_message, rag_results)
        }
        
        strategy = response_strategies.get(intent, response_strategies["general"])
        return strategy()

    # === M√âTHODES DE G√âN√âRATION DE R√âPONSES ===

    def _generate_natural_response(self, user_message, rag_results):
        """G√©n√®re une r√©ponse conversationnelle naturelle"""
        if rag_results["gemini_analysis"]:
            return self._create_response(rag_results["gemini_analysis"], 0.9, 'gemini')
        elif rag_results["knowledge_base"] and rag_results["knowledge_base"][0]['score'] > 0.5:
            best_match = rag_results["knowledge_base"][0]
            response_text = self._format_conversational_kb_response(best_match['qa_data'])
            return self._create_response(response_text, best_match['score'], 'knowledge_base')
        else:
            response_text = self._generate_improved_template_response(user_message)
            return self._create_response(response_text, 0.7, 'template_improved')

    def _generate_simple_response(self, user_message, rag_results):
        """G√©n√®re une r√©ponse simple et factuelle"""
        if rag_results["gemini_analysis"]:
            return self._create_response(rag_results["gemini_analysis"], 0.9, 'gemini')
        elif rag_results["knowledge_base"] and rag_results["knowledge_base"][0]['score'] > 0.6:
            best_match = rag_results["knowledge_base"][0]
            response_text = self._format_knowledge_response(best_match['qa_data'])
            return self._create_response(response_text, best_match['score'], 'knowledge_base')
        else:
            response_text = self._generate_factual_template(user_message, rag_results)
            return self._create_response(response_text, 0.7, 'template')

    def _generate_analytical_response(self, user_message, rag_results, context):
        """G√©n√®re une r√©ponse analytique approfondie"""
        if rag_results["gemini_analysis"]:
            return self._create_response(rag_results["gemini_analysis"], 0.9, 'gemini')
        else:
            response_text = self._generate_analytical_template(user_message, rag_results, context)
            return self._create_response(response_text, 0.75, 'template')

    def _generate_comparison_response(self, user_message, rag_results):
        """G√©n√®re une r√©ponse comparative"""
        if rag_results["gemini_analysis"]:
            return self._create_response(rag_results["gemini_analysis"], 0.9, 'gemini')
        else:
            response_text = self._generate_comparison_template(user_message, rag_results)
            return self._create_response(response_text, 0.7, 'template')

    def _generate_solution_response(self, user_message, rag_results):
        """G√©n√®re une r√©ponse de r√©solution de probl√®me"""
        response_text = self._generate_solution_template(user_message, rag_results)
        return self._create_response(response_text, 0.8, 'template')

    def _create_response(self, response_text, confidence, source):
        """Cr√©e une r√©ponse standardis√©e"""
        return {
            'type': 'success',
            'response': response_text,
            'confidence': confidence,
            'source': source
        }

    # === M√âTHODES GEMINI ===

    def _generate_with_gemini_fallback(self, user_message):
        """Utilise Gemini comme fallback quand aucune r√©ponse n'est trouv√©e"""
        try:
            prompt = self._build_gemini_fallback_prompt(user_message)
            response = self.gemini_model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print(f"‚ùå Erreur Gemini fallback: {e}")
            return self._generate_improved_template_response(user_message)

    def _build_gemini_fallback_prompt(self, user_message):
        """Construit le prompt pour le fallback Gemini"""
        return f"""
        Tu es un assistant expert pour ZamaPay, une plateforme de transfert d'argent 
        sp√©cialis√©e pour le Burkina Faso et l'Afrique de l'Ouest.
        
        Contexte Burkina Faso:
        - Devise: Franc CFA (XOF)
        - Op√©rateurs mobile money: Orange Money, Moov Money
        - Pays UEMOA: BF, CI, ML, SN, NE, TG, BJ, GW
        - R√©glementation: BCEAO
        - Support: 70 123 456
        - Langues: Fran√ßais, Moor√©, Dioula

        L'utilisateur pose la question suivante, mais elle n'est pas dans notre base de connaissances.
        R√©ponds de mani√®re utile et professionnelle en fran√ßais, adapt√©e au contexte burkinab√©.

        QUESTION: {user_message}

        Si la question concerne les transferts d'argent, les frais, les d√©lais, la s√©curit√©,
        donne une r√©ponse g√©n√©rale mais pr√©cise en F CFA. Si c'est hors sujet, redirige gentiment vers le support.

        IMPORTANT: Sois concis, utile et professionnel. Utilise un ton chaleureux mais expert.

        R√©ponse:
        """

    def _generate_with_gemini(self, user_message, context):
        """G√©n√®re une r√©ponse avec Gemini pour les questions complexes"""
        try:
            prompt = self._build_gemini_context_prompt(user_message, context)
            response = self.gemini_model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print(f"‚ùå Erreur Gemini: {e}")
            return None

    def _build_gemini_context_prompt(self, user_message, context):
        """Construit le prompt contextuel pour Gemini"""
        return f"""
        Tu es un assistant expert pour ZamaPay, une plateforme de transfert d'argent 
        sp√©cialis√©e pour le Burkina Faso et l'Afrique de l'Ouest.
        
        Contexte Burkina Faso:
        - Devise: Franc CFA (XOF)
        - Op√©rateurs mobile money: Orange Money, Moov Money
        - Pays UEMOA: BF, CI, ML, SN, NE, TG, BJ, GW
        - R√©glementation: BCEAO
        - Support: 70 123 456

        CONTEXTE SUPPL√âMENTAIRE:
        {context}

        QUESTION UTILISATEUR:
        {user_message}

        R√©ponds en fran√ßais, sois pr√©cis sur les montants en F CFA, 
        mentionne les d√©lais r√©els et les proc√©dures sp√©cifiques au Burkina.
        Si tu ne sais pas, oriente vers le support au 70 123 456.

        Ton style: Professionnel mais accessible, structur√© avec des sections claires.
        """

    def _build_rag_context(self, rag_results):
        """Construit un contexte RAG pour Gemini"""
        context_parts = []
        
        # Contexte de la base de connaissances
        if rag_results["knowledge_base"]:
            kb_context = "**Informations de la base ZamaPay :**\n"
            for i, result in enumerate(rag_results["knowledge_base"][:2], 1):
                kb_context += f"{i}. {result['qa_data']['reponse']}\n"
            context_parts.append(kb_context)
        
        # Contexte de la recherche web
        if rag_results["web_search"]:
            web_context = "**Informations web r√©centes :**\n"
            for i, result in enumerate(rag_results["web_search"][:2], 1):
                web_context += f"{i}. {result['content'][:300]}...\n"
            context_parts.append(web_context)
        
        return "\n\n".join(context_parts) if context_parts else None

    # === TEMPLATES ET FORMATTAGE ===

    def _init_quality_templates(self):
        """Initialise des templates de haute qualit√©"""
        return {
            "frais": [
                """**üí∞ Frais ZamaPay - Transparence Totale**

## Transferts Nationaux (Burkina Faso)
- **1%** du montant (minimum 500 F CFA)
- Exemple : 50,000 F CFA ‚Üí 500 F CFA de frais

## Transferts UEMOA (C√¥te d'Ivoire, Mali, S√©n√©gal...)
- **1.5%** du montant (minimum 750 F CFA) 
- Exemple : 100,000 F CFA ‚Üí 1,500 F CFA de frais

## Mobile Money (Orange Money, Moov Money)
- **1%** du montant (minimum 250 F CFA)
- Transfert instantan√©

üí° **Aucun frais cach√©** - Tout est visible avant validation !""",
            ],
            "delais": [
                """**‚è±Ô∏è D√©lais de Traitement**

## Transferts Standards
- **Burkina Faso** : 2 heures maximum
- **UEMOA** : 2-4 heures
- **Mobile Money** : Instantan√©

## Transferts Express (+500 F CFA)
- **15 minutes** pour toutes destinations UEMOA

üîÑ **Suivi en temps r√©el** dans l'application !""",
            ]
        }

    def _generate_improved_template_response(self, user_message):
        """G√©n√®re une r√©ponse template am√©lior√©e"""
        message_lower = user_message.lower()
        
        # D√©tection de salutation
        if any(word in message_lower for word in ["bonjour", "salut", "slt", "hello", "coucou"]):
            return random.choice([
                "üëã Bonjour ! Je suis l'assistant ZamaPay. Je peux vous aider avec :\n‚Ä¢ Transferts d'argent\n‚Ä¢ Frais et tarifs\n‚Ä¢ D√©lais de traitement\n‚Ä¢ S√©curit√© des transactions\n\nComment puis-je vous aider aujourd'hui ?",
                "üëã Salut ! Ravie de vous aider. Je suis sp√©cialis√© dans les services ZamaPay : transferts, frais, d√©lais, s√©curit√©. Quelle est votre question ?",
                "üëã Hello ! Assistant ZamaPay √† votre service. Je peux vous renseigner sur nos transferts, tarifs, d√©lais. Que souhaitez-vous savoir ?"
            ])
        
        # D√©tection de question sur ZamaPay
        elif any(word in message_lower for word in ["zamapay", "c'est quoi", "qu'est ce", "pr√©sentation"]):
            return self._get_zamapay_presentation()
        
        # R√©ponse par d√©faut am√©lior√©e
        else:
            return self._get_default_response(user_message)

    def _get_zamapay_presentation(self):
        """Retourne la pr√©sentation de ZamaPay"""
        return """**üí≥ ZamaPay - Votre partenaire de transfert d'argent en Afrique de l'Ouest**

üåü **Qui sommes-nous ?**
ZamaPay est une plateforme de transfert d'argent innovante, sp√©cialis√©e pour le Burkina Faso et toute l'Afrique de l'Ouest.

üéØ **Nos services principaux :**
- Transferts nationaux et internationaux
- Support multi-devises (F CFA, Euro, Dollar)
- Int√©gration Mobile Money (Orange Money, Moov Money)
- Transactions 100% s√©curis√©es

üí∏ **Nos tarifs transparents :**
- Transferts nationaux : 1% (min. 500 F CFA)
- Transferts UEMOA : 1.5% (min. 750 F CFA)
- Mobile Money : 1% (min. 250 F CFA)

üìû **Support client :** 70 123 456
üåç **Site web :** www.zamapay.com"""

    def _get_default_response(self, user_message):
        """Retourne une r√©ponse par d√©faut"""
        return f"""ü§ñ **Assistant ZamaPay**

Je vois que vous demandez : "{user_message}"

Je suis sp√©cialis√© dans l'assistance ZamaPay. Pour une r√©ponse pr√©cise et personnalis√©e, je vous recommande de :

**üìû Contacter notre support :**
‚Ä¢ T√©l√©phone : 70 123 456
‚Ä¢ Email : support@zamapay.com
‚Ä¢ Application : Chat en direct

**üîç Domaines o√π je peux vous aider :**
‚úì Transferts d'argent et frais
‚úì D√©lais de traitement  
‚úì S√©curit√© des transactions
‚úì Support compte et application

N'h√©sitez pas √† poser une question sp√©cifique sur nos services !"""

    def _format_conversational_kb_response(self, qa_data):
        """Formate une r√©ponse KB de fa√ßon conversationnelle"""
        return f"""**{qa_data['question_principale']}**

{qa_data['reponse']}

{self._get_conversational_suggestions(qa_data)}"""

    def _format_knowledge_response(self, qa_data):
        """Formate une r√©ponse de base de connaissances"""
        return f"""**{qa_data['question_principale']}**

{qa_data['reponse']}

{self._get_related_suggestions(qa_data)}"""

    def _get_conversational_suggestions(self, qa_data):
        """Sugg√®re des questions de fa√ßon conversationnelle"""
        related = []
        for related_id in qa_data.get('questions_connexes', []):
            related_qa = self.retrieval_system.get_qa_by_id(related_id)
            if related_qa:
                related.append(f"\"{related_qa['question_principale']}\"")
        
        if related:
            return f"\n**ü§î Questions connexes :** {', '.join(related[:2])}"
        return "\n**üí¨ Besoin de plus de d√©tails ?** Je suis l√† pour vous aider !"

    def _get_related_suggestions(self, qa_data):
        """Sugg√®re des questions connexes"""
        related = []
        for related_id in qa_data.get('questions_connexes', []):
            related_qa = self.retrieval_system.get_qa_by_id(related_id)
            if related_qa:
                related.append(f"‚Ä¢ {related_qa['question_principale']}")
        
        if related:
            return "\n**üí° Vous pourriez aussi aimer :**\n" + "\n".join(related[:2])
        return ""

    # === TEMPLATES SP√âCIALIS√âS ===

    def _generate_factual_template(self, user_message, rag_results):
        """G√©n√®re un template factuel"""
        return self._generate_improved_template_response(user_message)

    def _generate_analytical_template(self, user_message, rag_results, context):
        """G√©n√®re un template analytique"""
        return f"""**üîç Analyse ZamaPay**

Votre question n√©cessite une analyse approfondie. Pour une r√©ponse compl√®te et personnalis√©e, je vous recommande de contacter notre √©quipe d'experts.

**üìû Support sp√©cialis√© :** 70 123 456
**üìß Email technique :** experts@zamapay.com

Notre √©quipe pourra vous fournir une analyse d√©taill√©e adapt√©e √† votre situation sp√©cifique."""

    def _generate_comparison_template(self, user_message, rag_results):
        """G√©n√®re un template comparatif"""
        return f"""**üîÑ Comparaison ZamaPay**

Pour une comparaison d√©taill√©e avec d'autres solutions, notre √©quipe commerciale peut vous pr√©parer une √©tude personnalis√©e.

**üéØ Contact comparaison :** 70 123 456
**üíº Rendez-vous expert :** www.zamapay.com/rdv

Nous pouvons comparer : frais, d√©lais, s√©curit√©, fonctionnalit√©s selon vos besoins."""

    def _generate_solution_template(self, user_message, rag_results):
        """G√©n√®re un template de r√©solution de probl√®me"""
        return f"""**üõ†Ô∏è Support Technique ZamaPay**

Notre √©quipe technique est disponible pour r√©soudre votre probl√®me rapidement.

**üö® Support imm√©diat :**
‚Ä¢ T√©l√©phone : 70 123 456
‚Ä¢ Email : support@zamapay.com  
‚Ä¢ Chat : Application ZamaPay

**‚è±Ô∏è D√©lai d'intervention :** Moins de 30 minutes

*Merci de d√©crire pr√©cis√©ment le probl√®me pour une r√©solution plus rapide.*"""

    # === ANALYSE ET CONTEXTE ===

    def _analyze_intent(self, user_message):
        """Analyse l'intention de l'utilisateur"""
        message_lower = user_message.lower()
        
        intent_patterns = {
            "simple_fact": [
                "combien", "quel est", "quels sont", "quelle est", 
                "frais", "tarif", "d√©lai", "temps", "co√ªt", "prix"
            ],
            "complex_analysis": [
                "pourquoi", "comment", "explique", "d√©taill√©",
                "analyse", "comprendre", "fonctionne", "m√©canisme"
            ],
            "comparison": [
                "comparer", "diff√©rence", "avantage", "inconv√©nient",
                "mieux", "meilleur", "vs", "contre", "oppos√©"
            ],
            "problem_solving": [
                "probl√®me", "erreur", "bug", "marche pas", "ne fonctionne pas",
                "aide", "solution", "r√©soudre", "corriger", "r√©parer"
            ]
        }
        
        for intent, patterns in intent_patterns.items():
            if any(pattern in message_lower for pattern in patterns):
                return intent
        
        return "general"

    def _get_conversation_context(self, user_name):
        """R√©cup√®re le contexte de conversation"""
        if user_name and user_name in self.conversation_memory:
            return self.conversation_memory[user_name].get('last_topics', [])
        return []

    def _update_conversation_memory(self, user_name, user_message, response):
        """Met √† jour la m√©moire conversationnelle"""
        if user_name:
            if user_name not in self.conversation_memory:
                self.conversation_memory[user_name] = {'last_topics': [], 'message_count': 0}
            
            # Garder les 3 derniers sujets
            topic = self._extract_topic(user_message)
            if topic and topic not in self.conversation_memory[user_name]['last_topics']:
                self.conversation_memory[user_name]['last_topics'].insert(0, topic)
                self.conversation_memory[user_name]['last_topics'] = self.conversation_memory[user_name]['last_topics'][:3]
            
            self.conversation_memory[user_name]['message_count'] += 1

    def _extract_topic(self, message):
        """Extrait le sujet principal du message"""
        topics = {
            "frais": ["frais", "tarif", "co√ªt", "prix", "combien"],
            "delais": ["d√©lai", "temps", "quand", "dur√©e", "rapide"],
            "securite": ["s√©curit√©", "prot√©ger", "fraude", "crypt√©", "donn√©es"],
            "compte": ["compte", "profil", "connexion", "mot de passe", "inscription"],
            "transfert": ["transfert", "envoyer", "recevoir", "argent", "paiement"]
        }
        
        message_lower = message.lower()
        for topic, keywords in topics.items():
            if any(keyword in message_lower for keyword in keywords):
                return topic
        return "general"

# Exemple d'utilisation
if __name__ == "__main__":
    # Test rapide de la classe
    from retrieval_system import RetrievalSystem  # √Ä adapter selon votre impl√©mentation
    
    print("üß™ Test ResponseGenerator...")
    retrieval = RetrievalSystem()
    generator = ResponseGenerator(retrieval)
    
    test_questions = [
        "Bonjour",
        "Quels sont vos frais ?",
        "Comment √ßa marche ?"
    ]
    
    for question in test_questions:
        print(f"\nQ: {question}")
        response = generator.generate_response(question)
        print(f"A: {response['response'][:100]}...")
        print(f"Confiance: {response['confidence']}")
        
    
