import random
import json
import google.generativeai as genai
from web_searcher import WebSearcher

class ResponseGenerator:
    def __init__(self, retrieval_system):
        self.retrieval_system = retrieval_system
        self.web_searcher = WebSearcher()
        self.conversation_memory = {}
        self.escalation_threshold = 0.4
        
        # Configuration Gemini avec votre nouvelle cl√©
        self.gemini_api_key = "AIzaSyBge8Q1B4g-rT5nIuhIb4Dc99BuIZXy7Ak"
        try:
            genai.configure(api_key=self.gemini_api_key)
            self.gemini_model = genai.GenerativeModel('gemini-2.5-flash')
            print("‚úÖ Gemini configur√© avec succ√®s avec la nouvelle cl√©")
        except Exception as e:
            print(f"‚ùå Erreur configuration Gemini: {e}")
            self.gemini_model = None
        
        # Templates conversationnels am√©lior√©s
        self.conversation_templates = self._init_quality_templates()
    
    def generate_response(self, user_message, user_name=None):
        """G√©n√®re une r√©ponse conversationnelle naturelle avec RAG"""
        print(f"üí¨ Conversation: '{user_message}'")
        
        # 1. Analyse de la conversation et contexte
        conversation_context = self._get_conversation_context(user_name)
        intent = self._analyze_intent(user_message)
        
        # 2. Recherche RAG am√©lior√©e
        rag_results = self._enhanced_rag_search(user_message, intent)
        
        # 3. V√âRIFICATION : Si pas de r√©sultat dans la base, utiliser Gemini
        if (not rag_results["knowledge_base"] and 
            not rag_results["web_search"] and 
            self.gemini_model):
            print("üîç Aucune r√©ponse trouv√©e, utilisation de Gemini...")
            gemini_response = self._generate_with_gemini_fallback(user_message)
            if gemini_response:
                return {
                    'type': 'success',
                    'response': gemini_response,
                    'confidence': 0.8,
                    'source': 'gemini_fallback'
                }
        
        # 4. G√©n√©ration de r√©ponse conversationnelle
        if intent == "simple_fact":
            response = self._generate_simple_response(user_message, rag_results)
        elif intent == "complex_analysis":
            response = self._generate_analytical_response(user_message, rag_results, conversation_context)
        elif intent == "comparison":
            response = self._generate_comparison_response(user_message, rag_results)
        elif intent == "problem_solving":
            response = self._generate_solution_response(user_message, rag_results)
        else:
            response = self._generate_natural_response(user_message, rag_results)
        
        # 5. Mise √† jour de la m√©moire conversationnelle
        self._update_conversation_memory(user_name, user_message, response)
        
        return response
    
    def _enhanced_rag_search(self, user_message, intent):
        """Recherche RAG am√©lior√©e avec multiple sources"""
        results = {
            "knowledge_base": [],
            "web_search": [],
            "gemini_analysis": None,
            "confidence": 0.0
        }
        
        # Recherche dans la base de connaissances
        kb_results = self.retrieval_system.search(user_message)
        if kb_results:
            results["knowledge_base"] = kb_results
            results["confidence"] = max(results["confidence"], kb_results[0]['score'])
        
        # Recherche web pour les questions complexes ou actuelles
        if intent in ["complex_analysis", "comparison"] or results["confidence"] < 0.5:
            try:
                web_results = self.web_searcher.search_web(user_message, num_results=2)
                results["web_search"] = web_results
                if web_results:
                    results["confidence"] = max(results["confidence"], 0.6)
            except Exception as e:
                print(f"‚ö†Ô∏è Recherche web √©chou√©e: {e}")
        
        # Analyse Gemini pour les questions complexes
        if intent in ["complex_analysis", "problem_solving"] and self.gemini_model:
            try:
                context = self._build_rag_context(results)
                gemini_response = self._generate_with_gemini(user_message, context)
                if gemini_response:
                    results["gemini_analysis"] = gemini_response
                    results["confidence"] = max(results["confidence"], 0.9)
            except Exception as e:
                print(f"‚ö†Ô∏è Analyse Gemini √©chou√©e: {e}")
        
        return results
    
    def _generate_with_gemini_fallback(self, user_message):
        """Utilise Gemini comme fallback quand aucune r√©ponse n'est trouv√©e"""
        try:
            prompt = f"""
            Tu es un assistant expert pour ZamaPay, une plateforme de transfert d'argent 
            sp√©cialis√©e pour le Burkina Faso et l'Afrique de l'Ouest.
            
            Contexte Burkina Faso:
            - Devise: Franc CFA (XOF)
            - Op√©rateurs mobile money: Orange Money, Moov Money
            - Pays UEMOA: BF, CI, ML, SN, NE, TG, BJ, GW
            - R√©glementation: BCEAO
            - Support: 70 123 456
            - Langues: Fran√ßais, Moor√©, Dioula

            L'utilisateur pose la question suivante, mais elle n'est pas dans notre base de connaissances.
            R√©ponds de mani√®re utile et professionnelle en fran√ßais, adapt√©e au contexte burkinab√©.

            QUESTION: {user_message}

            Si la question concerne les transferts d'argent, les frais, les d√©lais, la s√©curit√©,
            donne une r√©ponse g√©n√©rale mais pr√©cise en F CFA. Si c'est hors sujet, redirige gentiment vers le support.

            IMPORTANT: Sois concis, utile et professionnel. Utilise un ton chaleureux mais expert.

            R√©ponse:
            """
            
            response = self.gemini_model.generate_content(prompt)
            return response.text.strip()
            
        except Exception as e:
            print(f"‚ùå Erreur Gemini fallback: {e}")
            return self._generate_improved_template_response(user_message)
    
    def _generate_with_gemini(self, user_message, context):
        """G√©n√®re une r√©ponse avec Gemini pour les questions complexes"""
        try:
            prompt = f"""
            Tu es un assistant expert pour ZamaPay, une plateforme de transfert d'argent 
            sp√©cialis√©e pour le Burkina Faso et l'Afrique de l'Ouest.
            
            Contexte Burkina Faso:
            - Devise: Franc CFA (XOF)
            - Op√©rateurs mobile money: Orange Money, Moov Money
            - Pays UEMOA: BF, CI, ML, SN, NE, TG, BJ, GW
            - R√©glementation: BCEAO
            - Support: 70 123 456

            CONTEXTE SUPPL√âMENTAIRE:
            {context}

            QUESTION UTILISATEUR:
            {user_message}

            R√©ponds en fran√ßais, sois pr√©cis sur les montants en F CFA, 
            mentionne les d√©lais r√©els et les proc√©dures sp√©cifiques au Burkina.
            Si tu ne sais pas, oriente vers le support au 70 123 456.

            Ton style: Professionnel mais accessible, structur√© avec des sections claires.
            """
            
            response = self.gemini_model.generate_content(prompt)
            return response.text.strip()
            
        except Exception as e:
            print(f"‚ùå Erreur Gemini: {e}")
            return None
    
    def _build_rag_context(self, rag_results):
        """Construit un contexte RAG pour Gemini"""
        context_parts = []
        
        # Contexte de la base de connaissances
        if rag_results["knowledge_base"]:
            kb_context = "**Informations de la base ZamaPay :**\n"
            for i, result in enumerate(rag_results["knowledge_base"][:2], 1):
                kb_context += f"{i}. {result['qa_data']['reponse']}\n"
            context_parts.append(kb_context)
        
        # Contexte de la recherche web
        if rag_results["web_search"]:
            web_context = "**Informations web r√©centes :**\n"
            for i, result in enumerate(rag_results["web_search"][:2], 1):
                web_context += f"{i}. {result['content'][:300]}...\n"
            context_parts.append(web_context)
        
        return "\n\n".join(context_parts) if context_parts else None
    
    def _generate_natural_response(self, user_message, rag_results):
        """G√©n√®re une r√©ponse conversationnelle naturelle"""
        if rag_results["gemini_analysis"]:
            response_text = rag_results["gemini_analysis"]
            confidence = 0.9
            source = 'gemini'
        elif rag_results["knowledge_base"] and rag_results["knowledge_base"][0]['score'] > 0.5:
            best_match = rag_results["knowledge_base"][0]
            response_text = self._format_conversational_kb_response(best_match['qa_data'])
            confidence = best_match['score']
            source = 'knowledge_base'
        else:
            response_text = self._generate_improved_template_response(user_message)
            confidence = 0.7
            source = 'template_improved'
        
        return {
            'type': 'success',
            'response': response_text,
            'confidence': confidence,
            'source': source
        }
    
    def _generate_simple_response(self, user_message, rag_results):
        """G√©n√®re une r√©ponse simple et factuelle"""
        if rag_results["gemini_analysis"]:
            response_text = rag_results["gemini_analysis"]
            confidence = 0.9
            source = 'gemini'
        elif rag_results["knowledge_base"] and rag_results["knowledge_base"][0]['score'] > 0.6:
            best_match = rag_results["knowledge_base"][0]
            response_text = self._format_knowledge_response(best_match['qa_data'])
            confidence = best_match['score']
            source = 'knowledge_base'
        else:
            response_text = self._generate_factual_template(user_message, rag_results)
            confidence = 0.7
            source = 'template'
        
        return {
            'type': 'success',
            'response': response_text,
            'confidence': confidence,
            'source': source
        }

    def _generate_improved_template_response(self, user_message):
        """G√©n√®re une r√©ponse template am√©lior√©e quand Gemini n'est pas disponible"""
        message_lower = user_message.lower()
        
        # D√©tection de salutation
        if any(word in message_lower for word in ["bonjour", "salut", "slt", "hello", "coucou"]):
            return random.choice([
                "üëã Bonjour ! Je suis l'assistant ZamaPay. Je peux vous aider avec :\n‚Ä¢ Transferts d'argent\n‚Ä¢ Frais et tarifs\n‚Ä¢ D√©lais de traitement\n‚Ä¢ S√©curit√© des transactions\n\nComment puis-je vous aider aujourd'hui ?",
                "üëã Salut ! Ravie de vous aider. Je suis sp√©cialis√© dans les services ZamaPay : transferts, frais, d√©lais, s√©curit√©. Quelle est votre question ?",
                "üëã Hello ! Assistant ZamaPay √† votre service. Je peux vous renseigner sur nos transferts, tarifs, d√©lais. Que souhaitez-vous savoir ?"
            ])
        
        # D√©tection de question sur ZamaPay
        elif any(word in message_lower for word in ["zamapay", "c'est quoi", "qu'est ce", "pr√©sentation"]):
            return """**üí≥ ZamaPay - Votre partenaire de transfert d'argent en Afrique de l'Ouest**

üåü **Qui sommes-nous ?**
ZamaPay est une plateforme de transfert d'argent innovante, sp√©cialis√©e pour le Burkina Faso et toute l'Afrique de l'Ouest.

üéØ **Nos services principaux :**
- Transferts nationaux et internationaux
- Support multi-devises (F CFA, Euro, Dollar)
- Int√©gration Mobile Money (Orange Money, Moov Money)
- Transactions 100% s√©curis√©es

üí∏ **Nos tarifs transparents :**
- Transferts nationaux : 1% (min. 500 F CFA)
- Transferts UEMOA : 1.5% (min. 750 F CFA)
- Mobile Money : 1% (min. 250 F CFA)

üìû **Support client :** 70 123 456
üåç **Site web :** www.zamapay.com"""

        # R√©ponse par d√©faut am√©lior√©e
        else:
            return f"""ü§ñ **Assistant ZamaPay**

Je vois que vous demandez : "{user_message}"

Je suis sp√©cialis√© dans l'assistance ZamaPay. Pour une r√©ponse pr√©cise et personnalis√©e, je vous recommande de :

**üìû Contacter notre support :**
‚Ä¢ T√©l√©phone : 70 123 456
‚Ä¢ Email : support@zamapay.com
‚Ä¢ Application : Chat en direct

**üîç Domaines o√π je peux vous aider :**
‚úì Transferts d'argent et frais
‚úì D√©lais de traitement  
‚úì S√©curit√© des transactions
‚úì Support compte et application

N'h√©sitez pas √† poser une question sp√©cifique sur nos services !"""

    def _init_quality_templates(self):
        """Initialise des templates de haute qualit√©"""
        return {
            "frais": [
                """**üí∞ Frais ZamaPay - Transparence Totale**

## Transferts Nationaux (Burkina Faso)
- **1%** du montant (minimum 500 F CFA)
- Exemple : 50,000 F CFA ‚Üí 500 F CFA de frais

## Transferts UEMOA (C√¥te d'Ivoire, Mali, S√©n√©gal...)
- **1.5%** du montant (minimum 750 F CFA) 
- Exemple : 100,000 F CFA ‚Üí 1,500 F CFA de frais

## Mobile Money (Orange Money, Moov Money)
- **1%** du montant (minimum 250 F CFA)
- Transfert instantan√©

üí° **Aucun frais cach√©** - Tout est visible avant validation !""",
            ],
            "delais": [
                """**‚è±Ô∏è D√©lais de Traitement**

## Transferts Standards
- **Burkina Faso** : 2 heures maximum
- **UEMOA** : 2-4 heures
- **Mobile Money** : Instantan√©

## Transferts Express (+500 F CFA)
- **15 minutes** pour toutes destinations UEMOA

üîÑ **Suivi en temps r√©el** dans l'application !""",
            ]
        }

    def _format_conversational_kb_response(self, qa_data):
        """Formate une r√©ponse KB de fa√ßon conversationnelle"""
        return f"""**{qa_data['question_principale']}**

{qa_data['reponse']}

{self._get_conversational_suggestions(qa_data)}"""

    def _format_knowledge_response(self, qa_data):
        """Formate une r√©ponse de base de connaissances"""
        return f"""**{qa_data['question_principale']}**

{qa_data['reponse']}

{self._get_related_suggestions(qa_data)}"""

    def _get_conversational_suggestions(self, qa_data):
        """Sugg√®re des questions de fa√ßon conversationnelle"""
        related = []
        for related_id in qa_data.get('questions_connexes', []):
            related_qa = self.retrieval_system.get_qa_by_id(related_id)
            if related_qa:
                related.append(f"\"{related_qa['question_principale']}\"")
        
        if related:
            return f"\n**ü§î Questions connexes :** {', '.join(related[:2])}"
        return "\n**üí¨ Besoin de plus de d√©tails ?** Je suis l√† pour vous aider !"

    def _get_related_suggestions(self, qa_data):
        """Sugg√®re des questions connexes"""
        related = []
        for related_id in qa_data.get('questions_connexes', []):
            related_qa = self.retrieval_system.get_qa_by_id(related_id)
            if related_qa:
                related.append(f"‚Ä¢ {related_qa['question_principale']}")
        
        if related:
            return "\n**üí° Vous pourriez aussi aimer :**\n" + "\n".join(related[:2])
        return ""

    def _analyze_intent(self, user_message):
        """Analyse l'intention de l'utilisateur"""
        message_lower = user_message.lower()
        
        # Mots-cl√©s pour chaque intention
        intent_patterns = {
            "simple_fact": [
                "combien", "quel est", "quels sont", "quelle est", 
                "frais", "tarif", "d√©lai", "temps", "co√ªt", "prix"
            ],
            "complex_analysis": [
                "pourquoi", "comment", "explique", "d√©taill√©",
                "analyse", "comprendre", "fonctionne", "m√©canisme"
            ],
            "comparison": [
                "comparer", "diff√©rence", "avantage", "inconv√©nient",
                "mieux", "meilleur", "vs", "contre", "oppos√©"
            ],
            "problem_solving": [
                "probl√®me", "erreur", "bug", "marche pas", "ne fonctionne pas",
                "aide", "solution", "r√©soudre", "corriger", "r√©parer"
            ]
        }
        
        for intent, patterns in intent_patterns.items():
            if any(pattern in message_lower for pattern in patterns):
                return intent
        
        return "general"

    def _generate_analytical_response(self, user_message, rag_results, context):
        """G√©n√®re une r√©ponse analytique approfondie"""
        if rag_results["gemini_analysis"]:
            response_text = rag_results["gemini_analysis"]
            confidence = 0.9
            source = 'gemini'
        else:
            response_text = self._generate_analytical_template(user_message, rag_results, context)
            confidence = 0.75
            source = 'template'
        
        return {
            'type': 'success',
            'response': response_text,
            'confidence': confidence,
            'source': source
        }

    def _generate_comparison_response(self, user_message, rag_results):
        """G√©n√®re une r√©ponse comparative"""
        if rag_results["gemini_analysis"]:
            response_text = rag_results["gemini_analysis"]
            confidence = 0.9
            source = 'gemini'
        else:
            response_text = self._generate_comparison_template(user_message, rag_results)
            confidence = 0.7
            source = 'template'
        
        return {
            'type': 'success',
            'response': response_text,
            'confidence': confidence,
            'source': source
        }

    def _generate_solution_response(self, user_message, rag_results):
        """G√©n√®re une r√©ponse de r√©solution de probl√®me"""
        response_text = self._generate_solution_template(user_message, rag_results)
        return {
            'type': 'success',
            'response': response_text,
            'confidence': 0.8,
            'source': 'template'
        }

    def _generate_factual_template(self, user_message, rag_results):
        """G√©n√®re un template factuel"""
        return self._generate_improved_template_response(user_message)

    def _generate_analytical_template(self, user_message, rag_results, context):
        """G√©n√®re un template analytique"""
        return f"""**üîç Analyse ZamaPay**

Votre question n√©cessite une analyse approfondie. Pour une r√©ponse compl√®te et personnalis√©e, je vous recommande de contacter notre √©quipe d'experts.

**üìû Support sp√©cialis√© :** 70 123 456
**üìß Email technique :** experts@zamapay.com

Notre √©quipe pourra vous fournir une analyse d√©taill√©e adapt√©e √† votre situation sp√©cifique."""

    def _generate_comparison_template(self, user_message, rag_results):
        """G√©n√®re un template comparatif"""
        return f"""**üîÑ Comparaison ZamaPay**

Pour une comparaison d√©taill√©e avec d'autres solutions, notre √©quipe commerciale peut vous pr√©parer une √©tude personnalis√©e.

**üéØ Contact comparaison :** 70 123 456
**üíº Rendez-vous expert :** www.zamapay.com/rdv

Nous pouvons comparer : frais, d√©lais, s√©curit√©, fonctionnalit√©s selon vos besoins."""

    def _generate_solution_template(self, user_message, rag_results):
        """G√©n√®re un template de r√©solution de probl√®me"""
        return f"""**üõ†Ô∏è Support Technique ZamaPay**

Notre √©quipe technique est disponible pour r√©soudre votre probl√®me rapidement.

**üö® Support imm√©diat :**
‚Ä¢ T√©l√©phone : 70 123 456
‚Ä¢ Email : support@zamapay.com  
‚Ä¢ Chat : Application ZamaPay

**‚è±Ô∏è D√©lai d'intervention :** Moins de 30 minutes

*Merci de d√©crire pr√©cis√©ment le probl√®me pour une r√©solution plus rapide.*"""

    def _get_conversation_context(self, user_name):
        """R√©cup√®re le contexte de conversation"""
        if user_name and user_name in self.conversation_memory:
            return self.conversation_memory[user_name].get('last_topics', [])
        return []

    def _update_conversation_memory(self, user_name, user_message, response):
        """Met √† jour la m√©moire conversationnelle"""
        if user_name:
            if user_name not in self.conversation_memory:
                self.conversation_memory[user_name] = {'last_topics': [], 'message_count': 0}
            
            # Garder les 3 derniers sujets
            topic = self._extract_topic(user_message)
            if topic and topic not in self.conversation_memory[user_name]['last_topics']:
                self.conversation_memory[user_name]['last_topics'].insert(0, topic)
                self.conversation_memory[user_name]['last_topics'] = self.conversation_memory[user_name]['last_topics'][:3]
            
            self.conversation_memory[user_name]['message_count'] += 1

    def _extract_topic(self, message):
        """Extrait le sujet principal du message"""
        topics = {
            "frais": ["frais", "tarif", "co√ªt", "prix", "combien"],
            "delais": ["d√©lai", "temps", "quand", "dur√©e", "rapide"],
            "securite": ["s√©curit√©", "prot√©ger", "fraude", "crypt√©", "donn√©es"],
            "compte": ["compte", "profil", "connexion", "mot de passe", "inscription"],
            "transfert": ["transfert", "envoyer", "recevoir", "argent", "paiement"]
        }
        
        message_lower = message.lower()
        for topic, keywords in topics.items():
            if any(keyword in message_lower for keyword in keywords):
                return topic
        return "general"
    